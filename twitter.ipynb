{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (1, 0), (2, 1), (3, 2), (4, 3), (5, 4), (2, 1), (6, 5), (7, 6), (8, 7), (9, 8), (10, 9), (11, 7), (12, 4), (13, 8), (14, 0), (15, 2), (16, 10)]\n",
      "1095\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import treebank\n",
    "corpus = treebank.tagged_sents()\n",
    "tree_corpus = []\n",
    "word_numbers = {}\n",
    "tag_numbers = {}\n",
    "for sent in corpus:\n",
    "    num_sent = []\n",
    "    for word, tag in sent:\n",
    "        wi = word_numbers.setdefault(word.lower(), len(word_numbers))\n",
    "        ti = tag_numbers.setdefault(tag, len(tag_numbers))\n",
    "        num_sent.append((wi, ti))\n",
    "    tree_corpus.append(num_sent)\n",
    "    \n",
    "print tree_corpus[0]\n",
    "print word_numbers.get(\"electricity\")\n",
    "print len(tag_numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "tweets = nltk.corpus.twitter_samples.tokenized()\n",
    "tweets_corpus = []\n",
    "for tweet in tweets:\n",
    "    tweet_sent = []\n",
    "    for word in tweet:\n",
    "        word = word.lower()\n",
    "        if word == \"rt\":\n",
    "            word = \"RETWEET_TOKEN\"\n",
    "        if word[0] == \"@\":\n",
    "            word = \"USER_TOKEN\"\n",
    "        if word[0] == \"#\":\n",
    "            word = \"HASHTAG_TOKEN\"\n",
    "        if word[0:8] == \"https://\" :\n",
    "            word = \"URL_TOKEN\"\n",
    "        if word[0:7] == \"http://\":\n",
    "            word = \"URL_TOKEN\"\n",
    "        wi = word_numbers.setdefault(word, len(word_numbers))\n",
    "        tweet_sent.append(wi)\n",
    "    tweets_corpus.append(tweet_sent)\n",
    "\n",
    "print tweets_corpus[0]\n",
    "print word_numbers.get(\"electricity\")\n",
    "print word_numbers.get(\"HASHTAG_TOKEN\")        \n",
    "print len(word_numbers)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tags = [\"USR\",\"HT\",\"RT\",\"URL\",\"VPP\",\"TD\",\"O\"]\n",
    "for tag in new_tags:\n",
    "    ti = tag_numbers.setdefault(tag, len(tag_numbers))\n",
    "\n",
    "word_numbers.setdefault('<unk>', len(word_numbers))\n",
    "\n",
    "word_names = [None] * len(word_numbers)\n",
    "for word, index in word_numbers.items():\n",
    "    word_names[index] = word\n",
    "tag_names = [None] * len(tag_numbers)\n",
    "for tag, index in tag_numbers.items():\n",
    "    tag_names[index] = tag\n",
    "    \n",
    "print word_numbers.get('<unk>')\n",
    "print len(tag_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "try:\n",
    "    urllib.request.urlretrieve(\"https://github.com/aritter/twitter_nlp/raw/master/data/annotated/pos.txt\",\"pos.txt\")\n",
    "except: # Python 2\n",
    "    urllib.urlretrieve(\"https://github.com/aritter/twitter_nlp/raw/master/data/annotated/pos.txt\",\"pos.txt\")\n",
    "test_corpora = []\n",
    "with open('pos.txt') as f:\n",
    "    words = []\n",
    "    for line in f:\n",
    "\n",
    "        if line.strip() == '':\n",
    "            test_corpora.append(words)\n",
    "            words = []\n",
    "        else:\n",
    "            word, tag = line.strip().split()\n",
    "\n",
    "            if tag == \"(\":\n",
    "                tag = \"-LRB-\"\n",
    "            if tag == \")\":\n",
    "                tag = \"-RRB-\"\n",
    "            if tag == \"NONE\":\n",
    "                tag = \"-NONE-\"   \n",
    "\n",
    "            word = word.lower()\n",
    "            if word == \"rt\":\n",
    "                word = \"RETWEET_TOKEN\"\n",
    "            if word[0] == \"@\":\n",
    "                word = \"USER_TOKEN\"\n",
    "            if word[0] == \"#\":\n",
    "                word = \"HASHTAG_TOKEN\"\n",
    "            if word[0:8] == \"https://\" :\n",
    "                word = \"URL_TOKEN\"\n",
    "            if word[0:7] == \"http://\":\n",
    "                word = \"URL_TOKEN\"\n",
    "            \n",
    "            if word_numbers.get(word) == None:\n",
    "                words.append((word_numbers.get('<unk>'),tag_numbers.get(tag)))\n",
    "            else:\n",
    "                words.append((word_numbers.get(word),tag_numbers.get(tag)))\n",
    "print test_corpora[0]\n",
    "\n",
    "test_outputs = []\n",
    "with open('pos.txt') as f:\n",
    "    words = []\n",
    "    for line in f:\n",
    "        if line.strip() == '':\n",
    "            test_outputs.append(words)\n",
    "            words = []\n",
    "        else:\n",
    "            word, tag = line.strip().split()\n",
    "            if tag == \"(\":\n",
    "                tag = \"-LRB-\"\n",
    "            if tag == \")\":\n",
    "                tag = \"-RRB-\"\n",
    "            if tag == \"NONE\":\n",
    "                tag = \"-NONE-\"   \n",
    "            words.append((word,tag))\n",
    "print len(tag_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def count(corpus,vocabulary,tagset):\n",
    "    S = len(tagset)\n",
    "    V = len(vocabulary)\n",
    "    eps = 0.1\n",
    "    pi = eps * np.ones(S)\n",
    "    transition = eps * np.ones((S, S))\n",
    "    emission = eps * np.ones((S, V))\n",
    "    for sent in corpus:\n",
    "        last_tag = None\n",
    "        for word, tag in sent:\n",
    "            emission[tag, word] += 1\n",
    "            if last_tag == None:\n",
    "                pi[tag] += 1\n",
    "            else:\n",
    "                transition[last_tag, tag] += 1\n",
    "            last_tag = tag\n",
    "    pi /= np.sum(pi)\n",
    "    for s in range(S):\n",
    "        emission[s,:] /= np.sum(emission[s,:])\n",
    "        transition[s,:] /= np.sum(transition[s,:])\n",
    "    return pi,transition,emission\n",
    "\n",
    "pi,transition,emission = count(tree_corpus,word_numbers,tag_numbers)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('USER_TOKEN', u'``'), (u'it', u'PRP'), (u\"'s\", u'VBZ'), (u'the', u'DT'), (u'view', u'NN'), (u'from', u'IN'), (u'where', u'WRB'), (u'i', u'PRP'), (u\"'m\", u'VBP'), (u'living', u'VBG'), (u'for', u'IN'), (u'two', u'CD'), (u'weeks', u'NNS'), (u'.', u'.'), (u'empire', u\"''\"), (u'state', u'NN'), (u'building', u'NN'), (u'=', u'.'), ('<unk>', u'-RRB-'), (u'.', u'.'), (u'pretty', u\"''\"), (u'bad', u'JJ'), (u'storm', u'NN'), (u'here', u'RB'), (u'last', u'JJ'), (u'evening', u'NN'), (u'.', u'.')]\n"
     ]
    }
   ],
   "source": [
    "def viterbi(params, observations):\n",
    "    prediction = []\n",
    "    pi, A, O = params\n",
    "    M = len(observations)\n",
    "    S = pi.shape[0]\n",
    "    \n",
    "    alpha = np.zeros((M, S))\n",
    "    alpha[:,:] = float('-inf')\n",
    "    backpointers = np.zeros((M, S), 'int')\n",
    "    \n",
    "    # base case\n",
    "    alpha[0, :] = pi * O[:,observations[0]]\n",
    "    \n",
    "    # recursive case\n",
    "    for t in range(1, M):\n",
    "        for s2 in range(S):\n",
    "            for s1 in range(S):\n",
    "                score = alpha[t-1, s1] * A[s1, s2] * O[s2, observations[t]]\n",
    "                if score > alpha[t, s2]:\n",
    "                    alpha[t, s2] = score\n",
    "                    backpointers[t, s2] = s1\n",
    "    \n",
    "    # now follow backpointers to resolve the state sequence\n",
    "    ss = []\n",
    "    ss.append(np.argmax(alpha[M-1,:]))\n",
    "    for i in range(M-1, 0, -1):\n",
    "        ss.append(backpointers[i, ss[-1]])\n",
    "    predict =  list(reversed(ss))\n",
    "    for i in range(len(predict)):\n",
    "        prediction.append((word_names[observations[i]],tag_names[predict[i]]))\n",
    "    return prediction\n",
    "\n",
    "\n",
    "predictions = []\n",
    "for sent in test_corpora:\n",
    "    encoded_sent = []\n",
    "    for word,tag in sent:\n",
    "        encoded_sent.append(word)\n",
    "    pred = viterbi((pi, transition, emission), encoded_sent)\n",
    "    predictions.append(pred)\n",
    "\n",
    "print predictions[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6371419163648337\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score as acc\n",
    "def evaluate(input):\n",
    "    output = []\n",
    "    for sent in input:\n",
    "        sents = []\n",
    "        for word,tag in sent:\n",
    "            sents.append(tag_numbers.get(tag))\n",
    "        output.append(sents)\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "pre_output =  evaluate(predictions)\n",
    "tweet_output = evaluate(test_outputs)\n",
    "all_test_tags = [tag for tags in tweet_output for tag in tags]\n",
    "all_pred_tags = [tag for tags in pre_output for tag in tags]\n",
    "print acc(all_test_tags, all_pred_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.15369893e-05 1.74752434e-04 8.32154448e-06 ... 8.32154448e-06\n",
      "  8.32154448e-06 8.32154448e-06]\n",
      " [1.33457894e-05 1.33457894e-05 6.51955158e-01 ... 1.33457894e-05\n",
      "  1.33457894e-05 1.33457894e-05]\n",
      " [1.62522347e-05 1.62522347e-05 1.62522347e-05 ... 1.62522347e-05\n",
      "  1.62522347e-05 1.62522347e-05]\n",
      " ...\n",
      " [3.83582662e-05 3.83582662e-05 3.83582662e-05 ... 3.83582662e-05\n",
      "  3.83582662e-05 3.83582662e-05]\n",
      " [3.83582662e-05 3.83582662e-05 3.83582662e-05 ... 3.83582662e-05\n",
      "  3.83582662e-05 3.83582662e-05]\n",
      " [3.83582662e-05 3.83582662e-05 3.83582662e-05 ... 3.83582662e-05\n",
      "  3.83582662e-05 3.83582662e-05]]\n"
     ]
    }
   ],
   "source": [
    "index_user_word = word_numbers.get('USER_TOKEN')\n",
    "index_hashtags_word = word_numbers.get('HASHTAG_TOKEN')\n",
    "index_retweet_word = word_numbers.get('RETWEET_TOKEN')\n",
    "index_URL_word = word_numbers.get('URL_TOKEN')\n",
    "\n",
    "index_user_tag = tag_numbers.get('USR')\n",
    "index_hashtags_tag = tag_numbers.get('HT')\n",
    "index_retweet_tag = tag_numbers.get('RT')\n",
    "index_URL_tag = tag_numbers.get('URL')\n",
    "\n",
    "for i in [index_hashtags_tag,index_user_tag,index_retweet_tag,index_URL_tag]:\n",
    "    for j in range(len(word_numbers)):\n",
    "        emission[i][j] = 0\n",
    "        \n",
    "emission[index_hashtags_tag][index_hashtags_word] = 1\n",
    "emission[index_user_tag][index_user_word] = 1\n",
    "emission[index_retweet_tag][index_retweet_word] = 1\n",
    "emission[index_URL_tag][index_URL_word] = 1\n",
    "\n",
    "\n",
    "print emission\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        NNP       0.60      0.27      0.37      1159\n",
      "          ,       0.85      1.00      0.92       303\n",
      "         CD       0.59      0.59      0.59       268\n",
      "        NNS       0.43      0.54      0.48       393\n",
      "         JJ       0.64      0.59      0.61       670\n",
      "         MD       0.53      0.97      0.69       181\n",
      "         VB       0.65      0.70      0.68       660\n",
      "         DT       0.74      0.93      0.82       825\n",
      "         NN       0.79      0.63      0.70      1931\n",
      "         IN       0.81      0.88      0.85      1091\n",
      "          .       0.72      0.83      0.77       875\n",
      "        VBZ       0.69      0.78      0.73       342\n",
      "        VBG       0.88      0.50      0.64       303\n",
      "         CC       0.96      0.88      0.92       305\n",
      "        VBD       0.77      0.74      0.75       306\n",
      "        VBN       0.43      0.63      0.51       140\n",
      "     -NONE-       0.00      0.00      0.00         2\n",
      "         RB       0.71      0.76      0.73       680\n",
      "         TO       0.84      0.96      0.90       264\n",
      "        PRP       0.86      0.82      0.84      1106\n",
      "        RBR       0.62      0.25      0.36        20\n",
      "        WDT       0.36      0.47      0.41        19\n",
      "        VBP       0.78      0.64      0.70       527\n",
      "         RP       0.64      0.45      0.53       110\n",
      "       PRP$       0.84      0.86      0.85       234\n",
      "        JJS       0.84      0.81      0.82        26\n",
      "        POS       0.39      0.78      0.52        36\n",
      "         ``       0.00      0.00      0.00         0\n",
      "         EX       0.38      0.80      0.52        10\n",
      "         ''       0.03      0.20      0.06        91\n",
      "         WP       0.97      0.74      0.84        47\n",
      "          :       0.97      0.76      0.85       562\n",
      "        JJR       0.48      0.74      0.58        31\n",
      "        WRB       1.00      0.81      0.90       143\n",
      "          $       0.00      0.00      0.00         0\n",
      "       NNPS       0.00      0.00      0.00         8\n",
      "        WP$       0.00      0.00      0.00         0\n",
      "      -LRB-       0.00      0.00      0.00        32\n",
      "      -RRB-       0.04      0.15      0.07        34\n",
      "        PDT       0.00      0.00      0.00         1\n",
      "        RBS       0.08      0.33      0.12         3\n",
      "         FW       0.00      0.00      0.00         3\n",
      "         UH       1.00      0.00      0.00       493\n",
      "        SYM       0.00      0.00      0.00        13\n",
      "         LS       0.00      0.00      0.00         1\n",
      "          #       0.00      0.00      0.00         0\n",
      "        USR       0.98      0.96      0.97       464\n",
      "         HT       0.98      0.98      0.98       135\n",
      "         RT       1.00      1.00      1.00       152\n",
      "        URL       0.99      0.90      0.95       183\n",
      "        VPP       0.00      0.00      0.00         1\n",
      "         TD       0.00      0.00      0.00         1\n",
      "          O       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.76      0.70      0.70     15185\n",
      "\n",
      "RT\n",
      "tag performe best \n",
      "[u'-NONE-', u'``', u'$', u'NNPS', u'WP$', u'-LRB-', u'PDT', u'FW', u'SYM', u'LS', u'#', 'VPP', 'TD', 'O']\n",
      "performe worse\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,precision_recall_fscore_support\n",
    "predictions = []\n",
    "for sent in test_corpora:\n",
    "    encoded_sent = []\n",
    "    for word,tag in sent:\n",
    "        encoded_sent.append(word)\n",
    "    pred = viterbi((pi, transition, emission), encoded_sent)\n",
    "    predictions.append(pred)\n",
    "\n",
    "pre_output =  evaluate(predictions)\n",
    "tweet_output = evaluate(test_outputs)\n",
    "all_test_tags = [tag for tags in tweet_output for tag in tags]\n",
    "all_pred_tags = [tag for tags in pre_output for tag in tags]\n",
    "result = classification_report(all_test_tags, all_pred_tags, target_names=tag_names)\n",
    "precision,recall,fscore,support = precision_recall_fscore_support(all_test_tags, all_pred_tags)\n",
    "listf = fscore.tolist()\n",
    "best = tag_names[listf.index(max(listf))]\n",
    "worse = min(listf)\n",
    "worselist = []\n",
    "for i in range(len(listf)):\n",
    "    if listf[i] == worse:\n",
    "        worselist.append(tag_names[i])\n",
    "\n",
    "        \n",
    "    \n",
    "print result\n",
    "print best \n",
    "print \"tag performe best \"\n",
    "print worselist \n",
    "print  \"performe worse\""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
